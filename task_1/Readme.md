Задача
Вам предстоит собрать информацию с сайта ​https://www.petsonic.com
Нас интересует та часть сайта, который занимается продажей товаров для животных - https://www.petsonic.com/farmacia-para-gatos/
Нужно собрать ​все товары​ из категории и записать в ​csv ​файл.

По каждому товару нужно собрать три параметра 
1. Полное название товара
2. Цену
3. Изображение

Пример разбора
-- картинка в документе

Такую страницу мы называем страницей мультипродукта. Это означает, что на одной странице находится информация о нескольких разновидностях продукта. В данном случае разная весовка: 200 gr, 430 gr, 4 kg.
      
С этой страницы в выходной файл должно быть добавлено 3 записи:
-- таблица в документе

Name
Price
Image
Galletas Granja para Perro - 200 gr
1.35
http://www.petsonic.com/5830-large_default/g alletas-granja-para-perro.jpg
Galletas Granja para Perro - 430 gr
2.34
http://www.petsonic.com/5830-large_default/g alletas-granja-para-perro.jpg
Galletas Granja para Perro - 4 kg
16.83
http://www.petsonic.com/5830-large_default/g alletas-granja-para-perro.jpg


* Ссылки на картинки могут быть разными у разных вариаций

На что обратить внимание
1. Название сформировано, как общее название продукта ​Galletas Granja para Perro плюс весовка из таблицы ​200 gr
2. Если у продуктов нет вариаций, то и весовка будет указана только одна. В таком случае с одной страницы продукта получится одна запись в файле
3. Список продуктов категории состоит из нескольких страниц

Требования к оформлению кода
1. Должна ​быть написана программа/скрипт на Ruby​. Программа получает на вход:
a. ссылка на страницу категории (может передаваться любая категория сайта)
b. имя файла в который будет записан результат
2. После отработки скрипта результаты записывает в выходной файл с заданными именем
3. В задании нужно использовать ​XPATH (не путать с CSS) ​для получения содержимого html элементов, таких как цена, название и т.п. [Зачеркнуто: Возможно, понадобится использовать regexp для того чтобы достать отдельные части данных, если xpath
недостаточно] Возможно, понадобится использовать regexp для того чтобы достать отдельные части данных, если xpath недостаточно.

4. Для скачивания страниц нужно использовать библиотеку ​curb,​ для парсинга страниц ​nokogiri​, для записи в csv файл – модуль ​csv
5. Скрипт должен работать достаточно быстро и при этом не привлекать к себе внимание администраторов сайта
6. Во время выполнения скрипта должно быть понятно, что он сейчас делает
